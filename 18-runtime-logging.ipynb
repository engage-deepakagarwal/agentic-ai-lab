{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\TFS\\Study\\agentic-ai\\.venv\\lib\\site-packages\\flaml\\__init__.py:20: UserWarning: flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n",
      "  warnings.warn(\"flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import autogen\n",
    "from autogen import AssistantAgent, UserProxyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"AOAI_CONFIG_LIST\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4o\"\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging session ID: caed33a2-82e9-46ff-ac41-e07684ae80b9\n"
     ]
    }
   ],
   "source": [
    "# Start logging\n",
    "logging_session_id = autogen.runtime_logging.start(config={\"dbname\": \"logs.db\"})\n",
    "print(\"Logging session ID: \" + str(logging_session_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent workflow and run it\n",
    "assistant = AssistantAgent(name=\"assistant\", llm_config= {\"config_list\": config_list})\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "What is the height of the Eiffel Tower? Only respond with the answer and terminate\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "The height of the Eiffel Tower is 330 meters. TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'What is the height of the Eiffel Tower? Only respond with the answer and terminate', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'The height of the Eiffel Tower is 330 meters. TERMINATE', 'role': 'user', 'name': 'assistant'}], summary='The height of the Eiffel Tower is 330 meters. ', cost={'usage_including_cached_inference': {'total_cost': 0.002605, 'gpt-4o-2024-05-13': {'cost': 0.002605, 'prompt_tokens': 482, 'completion_tokens': 13, 'total_tokens': 495}}, 'usage_excluding_cached_inference': {'total_cost': 0.002605, 'gpt-4o-2024-05-13': {'cost': 0.002605, 'prompt_tokens': 482, 'completion_tokens': 13, 'total_tokens': 495}}}, human_input=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    assistant, message=\"What is the height of the Eiffel Tower? Only respond with the answer and terminate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "autogen.runtime_logging.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Data from the SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log(dbname=\"logs.db\", table=\"chat_completions\"):\n",
    "    import sqlite3\n",
    "\n",
    "    con = sqlite3.connect(dbname)\n",
    "    query = f\"SELECT * from {table}\"\n",
    "    cursor = con.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    column_names = [description[0] for description in cursor.description]\n",
    "    data = [dict(zip(column_names, row)) for row in rows]\n",
    "    con.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>invocation_id</th>\n",
       "      <th>client_id</th>\n",
       "      <th>wrapper_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>is_cached</th>\n",
       "      <th>cost</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>aa5b69b6-ee76-42f8-9292-fb9d4adff22d</td>\n",
       "      <td>2222156761744</td>\n",
       "      <td>2222156766160</td>\n",
       "      <td>caed33a2-82e9-46ff-ac41-e07684ae80b9</td>\n",
       "      <td>assistant</td>\n",
       "      <td>You are a helpful AI assistant.\\nSolve tasks u...</td>\n",
       "      <td>The height of the Eiffel Tower is 330 meters. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>2024-12-29 16:00:17.908613</td>\n",
       "      <td>2024-12-29 16:00:19.224969</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                         invocation_id      client_id     wrapper_id  \\\n",
       "0   1  aa5b69b6-ee76-42f8-9292-fb9d4adff22d  2222156761744  2222156766160   \n",
       "\n",
       "                             session_id source_name  \\\n",
       "0  caed33a2-82e9-46ff-ac41-e07684ae80b9   assistant   \n",
       "\n",
       "                                             request  \\\n",
       "0  You are a helpful AI assistant.\\nSolve tasks u...   \n",
       "\n",
       "                                            response  is_cached      cost  \\\n",
       "0  The height of the Eiffel Tower is 330 meters. ...          0  0.002605   \n",
       "\n",
       "                   start_time                    end_time  total_tokens  \n",
       "0  2024-12-29 16:00:17.908613  2024-12-29 16:00:19.224969           495  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def str_to_dict(s):\n",
    "    return json.loads(s)\n",
    "\n",
    "\n",
    "log_data = get_log()\n",
    "log_data_df = pd.DataFrame(log_data)\n",
    "\n",
    "log_data_df[\"total_tokens\"] = log_data_df.apply(\n",
    "    lambda row: str_to_dict(row[\"response\"])[\"usage\"][\"total_tokens\"], axis=1\n",
    ")\n",
    "\n",
    "log_data_df[\"request\"] = log_data_df.apply(lambda row: str_to_dict(row[\"request\"])[\"messages\"][0][\"content\"], axis=1)\n",
    "\n",
    "log_data_df[\"response\"] = log_data_df.apply(\n",
    "    lambda row: str_to_dict(row[\"response\"])[\"choices\"][0][\"message\"][\"content\"], axis=1\n",
    ")\n",
    "\n",
    "log_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens for all sessions: 495, total cost: 0.0026\n",
      "Total tokens for session caed33a2-82e9-46ff-ac41-e07684ae80b9: 495, cost: 0.0026\n"
     ]
    }
   ],
   "source": [
    "# Sum totoal tokens for all sessions\n",
    "total_tokens = log_data_df[\"total_tokens\"].sum()\n",
    "\n",
    "# Sum total cost for all sessions\n",
    "total_cost = log_data_df[\"cost\"].sum()\n",
    "\n",
    "# Total tokens for specific session\n",
    "session_tokens = log_data_df[log_data_df[\"session_id\"] == logging_session_id][\"total_tokens\"].sum()\n",
    "session_cost = log_data_df[log_data_df[\"session_id\"] == logging_session_id][\"cost\"].sum()\n",
    "\n",
    "print(\"Total tokens for all sessions: \" + str(total_tokens) + \", total cost: \" + str(round(total_cost, 4)))\n",
    "print(\n",
    "    \"Total tokens for session \"\n",
    "    + str(logging_session_id)\n",
    "    + \": \"\n",
    "    + str(session_tokens)\n",
    "    + \", cost: \"\n",
    "    + str(round(session_cost, 4))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
