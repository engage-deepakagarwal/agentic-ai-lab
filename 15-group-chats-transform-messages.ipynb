{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen.agentchat.contrib.capabilities import transform_messages, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"AOAI_CONFIG_LIST\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4o\"\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of messages\n",
    "\n",
    "# Let's start by limiting the number of messages to consider for speaker selection using a\n",
    "# MessageHistoryLimiter transform. This example will use the latest 10 messages.\n",
    "\n",
    "select_speaker_transforms = transform_messages.TransformMessages(\n",
    "    transforms=[\n",
    "        transforms.MessageHistoryLimiter(max_messages=10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress messages through an LLM\n",
    "\n",
    "# An interesting and very powerful method of reducing tokens is by \"compressing\" the text of\n",
    "# a message by using an LLM that's specifically designed to do that. The default LLM used for\n",
    "# this purpose is LLMLingua (https://github.com/microsoft/LLMLingua) and it aims to reduce the\n",
    "# number of tokens without reducing the message's meaning. We use the TextMessageCompressor\n",
    "# transform to compress messages.\n",
    "\n",
    "# There are multiple LLMLingua models available and it defaults to the first version, LLMLingua.\n",
    "# This example will show how to use LongLLMLingua which is targeted towards long-context\n",
    "# information processing. LLMLingua-2 has been released and you could use that as well.\n",
    "\n",
    "# Create the compression arguments, which allow us to specify the model and other related\n",
    "# parameters, such as whether to use the CPU or GPU.\n",
    "select_speaker_compression_args = dict(\n",
    "    model_name=\"microsoft/llmlingua-2-xlm-roberta-large-meetingbank\", use_llmlingua2=True, device_map=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the cache functionality\n",
    "from autogen.cache.in_memory_cache import InMemoryCache\n",
    "\n",
    "# Important notes on the parameters `TextMessageCompressor` used:\n",
    "# min_tokens - will only apply text compression if the message has at least 1,000 tokens\n",
    "# cache - enables caching, if a message has previously been compressed it will use the\n",
    "#         cached version instead of recompressing it (making it much faster)\n",
    "# filter_dict - to minimise the chance of compressing key information, we can include or\n",
    "#         exclude messages based on role and name.\n",
    "#         Here, we are excluding any 'system' messages as well as any messages from\n",
    "#         'ceo' (just for example) and the 'checking_agent' (internally used), which is an agent in the\n",
    "#         nested chat speaker selection chat. Change the 'ceo' name or add additional\n",
    "#         agent names for any agents that have critical content.\n",
    "# exclude_filter - As we are setting this to True, the filter will be an exclusion filter.\n",
    "\n",
    "# We can also manage the total tokens and individual message tokens. We have added a\n",
    "# MessageTokenLimiter transform that will limit the total number of tokens for the messages to\n",
    "# 3,000 with a maximum of 500 per individual message. Additionally, if a message is less than 300\n",
    "# tokens it will not be truncated.\n",
    "\n",
    "\n",
    "select_speaker_transforms = transform_messages.TransformMessages(\n",
    "    transforms=[\n",
    "        transforms.MessageHistoryLimiter(max_messages=10),\n",
    "        transforms.TextMessageCompressor(\n",
    "            min_tokens=1000,\n",
    "            text_compressor=transforms.LLMLingua(select_speaker_compression_args, structured_compression=True),\n",
    "            cache=InMemoryCache(seed=43),\n",
    "            filter_dict={\"role\": [\"system\"], \"name\": [\"ceo\", \"checking_agent\"]},\n",
    "            exclude_filter=True,\n",
    "        ),\n",
    "        transforms.MessageTokenLimiter(max_tokens=3000, max_tokens_per_message=500, min_tokens=300),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we apply the transforms to a group chat. We do this by assigning the message\n",
    "# transforms from above to the `select_speaker_transform_messages` parameter on the GroupChat.\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your agents\n",
    "chief_executive_officer = autogen.ConversableAgent(\n",
    "    \"ceo\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    max_consecutive_auto_reply=1,\n",
    "    system_message=\"You are leading this group chat, and the business, as the chief executive officer.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_manager = autogen.ConversableAgent(\n",
    "    \"gm\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    max_consecutive_auto_reply=1,\n",
    "    system_message=\"You are the general manager of the business, running the day-to-day operations.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_controller = autogen.ConversableAgent(\n",
    "    \"fin_controller\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    max_consecutive_auto_reply=1,\n",
    "    system_message=\"You are the financial controller, ensuring all financial matters are managed accordingly.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_group_chat = autogen.GroupChat(\n",
    "    agents=[chief_executive_officer, general_manager, financial_controller],\n",
    "    select_speaker_transform_messages=select_speaker_transforms,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
