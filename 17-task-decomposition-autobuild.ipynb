{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AutoBuild`, a pipeline that can **automatically build multi-agent systems** for complex tasks. \n",
    "\n",
    "`AutoBuild` is an effective approach that generates a group of experts and use their conversation to solve a task. In `AutoBuild`, each expert handles a part of the task, therefore effectively and comprehensively solving it.\n",
    "\n",
    "`AgentBuilder`, which will complete the generation of participant expert agents and the construction of group chat automatically after the user provides descriptions of a building task and an execution task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOBUILD_SYSTEM_MESSAGE = \"\"\"You are a manager of a group of advanced experts, your primary objective is to delegate the resolution of tasks to other experts through structured dialogue and derive conclusive insights from their conversation summarization.\n",
    "When a task is assigned, it's crucial to assess its constraints and conditions for completion. If feasible, the task should be divided into smaller, logically consistent subtasks. Following this division, you have the option to address these subtasks by forming a team of agents using the \"autobuild\" tool.\n",
    "Upon the completion of all tasks and verifications, you should conclude the operation and reply \"TERMINATE\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Callable, Dict, Literal, Optional, Union\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "# Install the autogen package\n",
    "import autogen\n",
    "from autogen import (\n",
    "    Agent,\n",
    "    AssistantAgent,\n",
    "    ConversableAgent,\n",
    "    GroupChat,\n",
    "    GroupChatManager,\n",
    "    UserProxyAgent,\n",
    "    register_function,\n",
    ")\n",
    "from autogen.agentchat.contrib import agent_builder\n",
    "from autogen.cache import Cache\n",
    "from autogen.coding import DockerCommandLineCodeExecutor, LocalCommandLineCodeExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"AOAI_CONFIG_LIST\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4o\"\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "autobuild_assistant = AssistantAgent(\n",
    "    name=\"Autobuild Assistant\",\n",
    "    llm_config={\"config_list\": config_list, \"cache_seed\": None},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autobuild_reply(recipient, messages, sender, config):\n",
    "    last_msg = messages[-1][\"content\"]\n",
    "    builder = agent_builder.AgentBuilder(\n",
    "        config_file_or_env=\"AOAI_CONFIG_LIST\",\n",
    "        builder_model=\"gpt-4o\",\n",
    "        agent_model=\"gpt-4o\",\n",
    "    )\n",
    "    agent_list, agent_configs = builder.build(\n",
    "        last_msg, \n",
    "        default_llm_config={\"config_list\": config_list, \"cache_seed\": None},\n",
    "        coding=True,\n",
    "        code_execution_config= {\n",
    "            \"work_dir\": \"coding\",\n",
    "            \"use_docker\": False\n",
    "        }\n",
    "    )\n",
    "    # start nested chat\n",
    "    nested_group_chat = GroupChat(\n",
    "        agents=agent_list,\n",
    "        messages=[],\n",
    "    )\n",
    "    manager = GroupChatManager(groupchat=nested_group_chat, llm_config={\"config_list\": config_list, \"cache_seed\": None})\n",
    "    chat_res = agent_list[0].initiate_chat(\n",
    "        manager, message=agent_configs.get(\"building_task\", last_msg), summary_method=\"reflection_with_llm\"\n",
    "    )\n",
    "    return True, chat_res.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "autobuild_assistant.register_reply([Agent, None], autobuild_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = (\n",
    "    f\"Today is {datetime.now().date()}. Write a blogpost about the stock price performance of Nvidia in the past month.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Cache.disk(cache_seed=41) as cache:\n",
    "    user_proxy.initiate_chat(autobuild_assistant, message=task, max_turns=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
